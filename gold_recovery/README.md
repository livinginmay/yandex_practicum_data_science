# Восстановление золота из руды

## Описание
Задача регрессии. В проекте рассмотрены 3 модели с подбором гиперпараметров на кросс-валидации. Используется функция расчета значения метрики.

## Данные
Данные были представлены в трех файлах:
* `gold_recovery_train_new.csv` – обучающая выборка;
* `gold_recovery_test_new.csv` – тестовая выборка;
* `gold_recovery_full_new.csv` – исходные данные.

И содержали следующую информацию:
* Характеристики этапа `state`, параметры сырья `input` и продукта `output` для этапов
1. Флотация `rougher`
2. Первичная очистка `primary_cleaner`
3. Вторичная очистка `secondary_cleaner`
4. Финальные характеристики `final`
* Расчетные характеристики флотации `calculation`.

## Задача
Необходимо разработать модель предсказания коэффициента восстановления золота из золотосодержащей руды с целью оптимизации производства, чтобы не запускать предприятие с убыточными характеристиками. Нужно спрогнозировать две величины:
*	Эффективность обогащения чернового концентрата `rougher.output.recovery`;
*	Эффективность обогащения финального концентрата `final.output.recovery`.
*	
Метрика качества:

$$
sMAPE_{итоговое} = 0.25 sMAPE_{rougher} + 0.75 sMAPE_{final}
$$
 
## Статус
Завершен

## Результат
Провела обучение разных моделей с подбором гиперпараметров и оценкой качества кросс-валидацией.

Лучшей моделью оказался случайный лес - для обоих целевых признаков - с разными гиперпараметрами:
* количество деревьев 49, максимальная глубина дерева 6 для `rougher.output.recovery`.
* количество деревьев 42, максимальная глубина дерева 4 для `final.output.recovery`.

Итоговая sMAPE на тестовой выборке составила 7.328, что лучше результата наивной модели, равного 7.778. Это означает, что модель ошибается в рамках 7.3%.

Такую небольшую разницу относительно наивной модели можно объяснить тем, что в обоих случаях большинство значений целевых признаков лежат в диапазоне с разницей 6-11% (84-89 для первого и 65-73 для второго). Большей разницей в случае второго целевого признака кстати объясняется и более высокая sMAPE.

## Используемые библиотеки
*Pandas, Scikit-learn, Seaborn*
